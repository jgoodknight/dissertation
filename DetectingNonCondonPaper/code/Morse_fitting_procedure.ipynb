{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting a Morse Diatomic Absorption spectrum with a non-Condon Moment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these spectroscopy calculations, we are given $\\omega_e$, $\\chi_e \\omega_e$, the reduced mass $\\mu$ and the equilibrium position $r_e$.  For each atom, we want to create a system of units out of these.\n",
    "\n",
    "\\begin{align}\n",
    "    h &= A \\cdot e_u\\cdot T_u = A \\cdot m_u \\frac{l_u^2}{T_u}\n",
    "\\end{align}\n",
    "lower case means we are setting it still, capital letters mean they are determined.  If we assume right now we want to set $E_u$ to be some spectoscopic value in wavenumbers and set $\\hbar$ then we know we have to let time float, which is fine since this code is not a time-dependent one.\n",
    "\\begin{align}\n",
    "    A \\cdot T_u &= \\frac{h}{e_u} \\\\\n",
    "    e_u &=  m_u \\frac{l_u^2}{T_u^2} \\\\\n",
    "    T_u &= \\sqrt{ \\frac{ m_u l_u^2}{e_u} }\\\\\n",
    "    h &= A e_u T_u \\\\\n",
    "    &= A e_u \\sqrt{ \\frac{ m_u l_u^2}{e_u} }\\\\\n",
    "    &= A  \\sqrt{ e_u m_u l_u^2 } \\\\\n",
    "    A &= \\frac{h}{\\sqrt{ e_u m_u l_u^2 }}\n",
    "\\end{align}\n",
    "so we can clearly only select either the mass or the length to fix in a system of units which is self-consistent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Angular Frequency Implication?\n",
    "According to Bob Field's book \"The Spectra and Dynamics of Diatomic Molecules: Revised and Enlarged Edition\", he defines $\\omega_e$ as:\n",
    "\\begin{align}\n",
    "    \\omega_e = \\hbar \\frac{1}{hc} \\sqrt{\\frac{k}{\\mu}}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joseph/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n",
      "/Users/joseph/anaconda/lib/python2.7/site-packages/pandas/computation/__init__.py:19: UserWarning: The installed version of numexpr 2.4.4 is not supported in pandas and will be not be used\n",
      "\n",
      "  UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"http://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"7cdb647b-d001-497d-8e18-81dbaf6c9fe9\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(global) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (window._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    window._bokeh_onload_callbacks = [];\n",
       "    window._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "\n",
       "  \n",
       "  if (typeof (window._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    window._bokeh_timeout = Date.now() + 5000;\n",
       "    window._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    if (window.Bokeh !== undefined) {\n",
       "      document.getElementById(\"7cdb647b-d001-497d-8e18-81dbaf6c9fe9\").textContent = \"BokehJS successfully loaded.\";\n",
       "    } else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    window._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    delete window._bokeh_onload_callbacks\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    window._bokeh_onload_callbacks.push(callback);\n",
       "    if (window._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    window._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        window._bokeh_is_loading--;\n",
       "        if (window._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"7cdb647b-d001-497d-8e18-81dbaf6c9fe9\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '7cdb647b-d001-497d-8e18-81dbaf6c9fe9' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.4.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "      document.getElementById(\"7cdb647b-d001-497d-8e18-81dbaf6c9fe9\").textContent = \"BokehJS is loading...\";\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.4.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.4.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.4.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.4.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((window.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i](window.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!window._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      window._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"7cdb647b-d001-497d-8e18-81dbaf6c9fe9\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (window._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(this));"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "from scipy.special import gamma, genlaguerre\n",
    "\n",
    "import scipy.integrate\n",
    "import scipy.misc\n",
    "\n",
    "import sympy.mpmath\n",
    "import sympy.functions.combinatorial.factorials as fact\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from bokeh.io import output_notebook, show\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#PROGRAM CONSTANTS\n",
    "STARTING_NUM_X_POINTS = 75\n",
    "STARTING_NUM_STDEV_FOR_INTEGRATING = 5.0\n",
    "DX_FACTOR_FOR_CONVERGENCE_CHECK = .8\n",
    "DEFAULT_ZERO_TOLERANCE = 1.0E-5\n",
    "\n",
    "ROOM_TEMPERATURE_KELVIN = 298.0\n",
    "\n",
    "#UNIT CONSTANTS\n",
    "kg_per_amu = 1.660468E-27\n",
    "h_joules_seconds = 6.62607E-34 #Joule*seconds\n",
    "hc_joules_centimeters = 1.9864458E-23\n",
    "m_per_angstrom = 1.0E-10\n",
    "k_B_wavenumbers_per_kelvin = .695035"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TEST DICTIONARIES\n",
    "TEST1_SYSTEM_DICTIONARY = {\"reduced_mass\" : 1.0,\n",
    "                      \"alpha\" : 1.0,\n",
    "                      \"center\" : 0.0,\n",
    "                      \"D\" : 2.0}\n",
    "TEST2_SYSTEM_DICTIONARY = {\"reduced_mass\" : 1.0,\n",
    "                      \"alpha\" : 1.5,\n",
    "                      \"center\" : 0.5,\n",
    "                      \"D\" : 1.0}\n",
    "\n",
    "TEST_UNIVERSE_DICTIONARY = {\"hbar\" : 1.0 / (2.0 * np.pi),\n",
    "                               \"ZERO_TOLERANCE\" : DEFAULT_ZERO_TOLERANCE,\n",
    "                            \"k_B\" : 1.0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6.6260699999999994e-34, 6.62607e-34)\n"
     ]
    }
   ],
   "source": [
    "#NITROGEN\n",
    "Nitrogen_energy_scale_wavenumbers = 2358.57\n",
    "Nitrogen_mass_scale_amu = 7.001537\n",
    "\n",
    "Nitrogen_center_offset_angstroms = 1.097685\n",
    "Nitrogen_length_scale_angstroms = 1.2203 - 1.097685\n",
    "\n",
    "Nitrogen_energy_scale_joule = Nitrogen_energy_scale_wavenumbers * hc_joules_centimeters\n",
    "Nitrogen_mass_scale_kg = Nitrogen_mass_scale_amu * kg_per_amu\n",
    "Nitrogen_length_scale_m = Nitrogen_length_scale_angstroms * m_per_angstrom\n",
    "\n",
    "h_nitrogen_units = h_joules_seconds / np.sqrt(Nitrogen_energy_scale_joule * Nitrogen_mass_scale_kg * Nitrogen_length_scale_m**2)\n",
    "Nitrogen_time_scale_seconds = np.sqrt(Nitrogen_mass_scale_kg * Nitrogen_length_scale_m**2 / Nitrogen_energy_scale_joule)\n",
    "\n",
    "k_B_Nitrogen_energy_per_K = k_B_wavenumbers_per_kelvin / Nitrogen_energy_scale_wavenumbers\n",
    "\n",
    "Nitrogen_universe_dictionary = {\"hbar\" : h_nitrogen_units / (2.0 * np.pi),\n",
    "                               \"ZERO_TOLERANCE\" : 1.0E-5,\n",
    "                                \"k_B\" : k_B_Nitrogen_energy_per_K}\n",
    "Nitrogen_Chi_1_Sigma_g_Plus = {\"omega_e\" : 2358.57 / Nitrogen_energy_scale_wavenumbers,\n",
    "                               \"chi_e_omega_e\" : 14.324 / Nitrogen_energy_scale_wavenumbers,\n",
    "                               \"reduced_mass\" : 7.001537 / Nitrogen_mass_scale_amu, \n",
    "                               \"center\" : (1.097685 - Nitrogen_center_offset_angstroms) / Nitrogen_length_scale_angstroms}\n",
    "Nitrogen_a_1_Pi_g = {\"omega_e\" : 1694.208 / Nitrogen_energy_scale_wavenumbers,\n",
    "                               \"chi_e_omega_e\" : 13.949 / Nitrogen_energy_scale_wavenumbers,\n",
    "                               \"reduced_mass\" : 7.001537 / Nitrogen_mass_scale_amu, \n",
    "                               \"center\" : (1.2203 - Nitrogen_center_offset_angstroms) / Nitrogen_length_scale_angstroms}\n",
    "print(h_nitrogen_units * Nitrogen_energy_scale_joule * Nitrogen_time_scale_seconds, h_joules_seconds)\n",
    "assert(np.abs(h_nitrogen_units * Nitrogen_energy_scale_joule * Nitrogen_time_scale_seconds -h_joules_seconds) < DEFAULT_ZERO_TOLERANCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class UnboundStateIndexError(Exception):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "class Morse(object):\n",
    "    def __init__(self, system_dictionary , universe_dictionary ):\n",
    "        \n",
    "        #define the Universe\n",
    "        self.hbar = universe_dictionary[\"hbar\"]\n",
    "        self.ZERO_TOLERANCE = universe_dictionary[\"ZERO_TOLERANCE\"]\n",
    "        self.k_B = universe_dictionary[\"k_B\"]\n",
    "        \n",
    "        #define the system\n",
    "        #terminology taken from Matsumoto and Iwamoto, 1993\n",
    "        self.mu = system_dictionary[\"reduced_mass\"]\n",
    "        self.center = system_dictionary[\"center\"]\n",
    "        self.r = self.center\n",
    "        \n",
    "        if \"alpha\" in system_dictionary:\n",
    "            self.alpha = system_dictionary[\"alpha\"]\n",
    "            self.D = system_dictionary[\"D\"]\n",
    "\n",
    "            self.omega_e = 2.0 * self.alpha * np.sqrt(self.D / (2.0 * self.mu))\n",
    "            self.chi_e_omega_e = self.alpha**2 * self.hbar / (2.0 * self.mu)\n",
    "        else:\n",
    "            self.omega_e = system_dictionary[\"omega_e\"]\n",
    "            self.chi_e_omega_e = system_dictionary[\"chi_e_omega_e\"]\n",
    "            \n",
    "            self.alpha = np.sqrt(2.0 * self.mu * self.chi_e_omega_e / self.hbar)\n",
    "            self.D = 2.0 * self.mu *(self.omega_e / (2.0 * self.alpha))**2\n",
    "            \n",
    "        \n",
    "        self.a = np.sqrt(2.0 * self.mu * self.D) / (self.alpha * self.hbar)\n",
    "        self.maximum_index = int(np.floor(self.a - .5))\n",
    "        \n",
    "        #Harmonic Oscillator Approximation:\n",
    "        k = self.potential_energy_gradientSquared(self.r)\n",
    "        self.omega_HO = np.sqrt(k / self.mu)\n",
    "        self.x0 = np.sqrt( self.hbar / (2.0 * self.omega_HO * self.mu))\n",
    "        \n",
    "        #determine the needed spatial parameters:\n",
    "        self.index_to_xParams_dictionary = {}\n",
    "        for energy_index in range(self.maximum_index + 1):\n",
    "            #use the analytically calculated spread of the corresponding HO wavefunction to start guessing the needed spatial parameters\n",
    "            HO_spatial_spread = self.x0 * np.sqrt(2 * energy_index + 1)\n",
    "            \n",
    "            x_min = self.r - STARTING_NUM_STDEV_FOR_INTEGRATING * HO_spatial_spread\n",
    "            while np.abs(self.energy_eigenfunction_amplitude(energy_index, x_min)) > self.ZERO_TOLERANCE:\n",
    "                x_min += -HO_spatial_spread\n",
    "            x_max = self.r + STARTING_NUM_STDEV_FOR_INTEGRATING * HO_spatial_spread           \n",
    "            while np.abs(self.energy_eigenfunction_amplitude(energy_index, x_max)) > self.ZERO_TOLERANCE:\n",
    "                x_max += HO_spatial_spread\n",
    "            \n",
    "            keep_integrating = True\n",
    "            \n",
    "            number_x_points = STARTING_NUM_X_POINTS\n",
    "            while keep_integrating:\n",
    "                x_vals = np.linspace(x_min, x_max, number_x_points)\n",
    "                psi_vals = self.energy_eigenfunction_amplitude(energy_index, x_vals)\n",
    "                integral = scipy.integrate.simps(np.conj(psi_vals) * psi_vals, x = x_vals)\n",
    "                if np.abs(integral - 1.0) < self.ZERO_TOLERANCE:\n",
    "                    keep_integrating = False\n",
    "                else:\n",
    "                    number_x_points = number_x_points + 10\n",
    "            dx = x_vals[1] - x_vals[0]\n",
    "            self.index_to_xParams_dictionary[energy_index] = (x_min, x_max, number_x_points, dx)\n",
    "            \n",
    "            \n",
    "        \n",
    "    \n",
    "    #POTENTIAL ENERGY STUFF:\n",
    "    def potential_energy(self, x):\n",
    "        return -2 * self.D * np.exp(- self.alpha * (x - self.r)) + self.D * np.exp(-2.0 * self.alpha * (x - self.r))\n",
    "    \n",
    "    def potential_energy_gradient(self, x):\n",
    "        return 2.0 * self.alpha * self.D *(np.exp(- self.alpha * (x - self.r)) - np.exp(-2.0 * self.alpha * (x - self.r)))\n",
    "        \n",
    "    def potential_energy_gradientSquared(self, x):\n",
    "        return 2.0 * self.alpha**2 * self.D *(-np.exp(- self.alpha * (x - self.r))  + 2.0 * np.exp(-2.0 * self.alpha * (x - self.r)))\n",
    "    \n",
    "    #ENERGY EIGENFUNCTION STUFF:\n",
    "    def energy_eigenvalue(self, index):\n",
    "        return -self.D + self.hbar * ( self.omega_e *(index + .5) - self.chi_e_omega_e *(index + .5)**2 )\n",
    "    \n",
    "    def energy_eigenfunction_amplitude(self, n, x):\n",
    "        if n > self.maximum_index:\n",
    "            raise UnboundStateIndexError()\n",
    "        b_n = self.a - .5 - n\n",
    "        N_n = np.sqrt(2.0 * self.alpha * b_n * scipy.misc.factorial(n) / gamma(2 * b_n + n + 1))\n",
    "        z = 2.0 * self.a * np.exp(-self.alpha *(x - self.r))\n",
    "        \n",
    "        z_poly = np.power(z, b_n)\n",
    "        z_exp = np.exp(-.5 * z)\n",
    "        lag_part = genlaguerre(n, 2 * b_n)(z)\n",
    "        \n",
    "        return N_n * z_poly * z_exp * lag_part\n",
    "    \n",
    "    def x_values_for_energy_eigenfunction(self, n):\n",
    "        x_min, x_max, num_x_points, dx = self.index_to_xParams_dictionary[n]\n",
    "        return np.linspace(x_min, x_max, num_x_points)\n",
    "    \n",
    "    #THERMAL FUNCTIONS\n",
    "    def partition_function_bound_state(self, T_Kelvin):\n",
    "        energies = []\n",
    "        for energy_index in range(self.maximum_index + 1):\n",
    "            energies.append(self.energy_eigenvalue(energy_index))\n",
    "        energies = np.array(energies)\n",
    "        boltzman_factors = np.exp(-energies / (self.k_B * T_Kelvin))\n",
    "        return np.sum(boltzman_factors)\n",
    "    \n",
    "    def thermal_weight_state_i(self, i, T_Kelvin):\n",
    "        e_i = self.energy_eigenvalue(i)\n",
    "        boltzmann_factor = np.exp(-e_i/(self.k_B * T_Kelvin))\n",
    "        return boltzmann_factor / self.partition_function_bound_state(T_Kelvin)\n",
    "    \n",
    "class OffsetMorse(object):\n",
    "    \n",
    "    def __init__(self, ground_morse, excited_morse, universe_dictionary ):\n",
    "        #define the Universe\n",
    "        self.hbar = universe_dictionary[\"hbar\"]\n",
    "        self.ZERO_TOLERANCE = universe_dictionary[\"ZERO_TOLERANCE\"]\n",
    "        \n",
    "        #assign variables\n",
    "        self.ground_morse = ground_morse\n",
    "        self.excited_morse = excited_morse\n",
    "        \n",
    "        self.franck_condon_factors = np.zeros((self.ground_morse.maximum_index + 1, self.excited_morse.maximum_index + 1))\n",
    "        for ground_index in range(self.ground_morse.maximum_index + 1):\n",
    "            #get the ground state's needed x parameters\n",
    "            ground_xMin, ground_xMax, ground_numPoints, ground_dx = self.ground_morse.index_to_xParams_dictionary[ground_index]\n",
    "            \n",
    "            for excited_index in range(self.excited_morse.maximum_index + 1 ):\n",
    "                #get the excited state's needed x parameters\n",
    "                excited_xMin, excited_xMax, excited_numPoints, excited_dx = self.excited_morse.index_to_xParams_dictionary[excited_index]\n",
    "                \n",
    "                #make best guess for needed x values for integrating the overlap\n",
    "                x_min = min([ground_xMin, excited_xMin])\n",
    "                x_max = max([excited_xMax, ground_xMax])\n",
    "                dx_needed = min([ground_dx, excited_dx]) \n",
    "                \n",
    "                new_dx = 1.0 / (1.0/ground_dx + 1.0/excited_dx)\n",
    "                \n",
    "                #integrate once\n",
    "                x_vals = np.arange(x_min, x_max, new_dx)\n",
    "                g_func_vals = self.ground_morse.energy_eigenfunction_amplitude(ground_index, x_vals)\n",
    "                e_func_vals = self.excited_morse.energy_eigenfunction_amplitude(excited_index, x_vals)\n",
    "                amp_to_integrate = e_func_vals * np.conj(g_func_vals)\n",
    "                old_integral = scipy.integrate.simps(amp_to_integrate, x= x_vals)\n",
    "                \n",
    "                if np.isnan(old_integral):\n",
    "                    for index, data in enumerate(amp_to_integrate):\n",
    "                        if np.isnan(data):\n",
    "                            amp_to_integrate[index] = 0.0\n",
    "                    old_integral = scipy.integrate.simps(amp_to_integrate, x= x_vals)\n",
    "                    nan_issue_encountered = True\n",
    "                else:\n",
    "                    nan_issue_encountered = False\n",
    "                    \n",
    "                \n",
    "                #check to make sure integral is converged\n",
    "                keep_integrating = True\n",
    "                number_failures = 0\n",
    "                max_failures = 5\n",
    "                calculated_integrals = [old_integral]\n",
    "                while keep_integrating:\n",
    "                    dx_needed = dx_needed * DX_FACTOR_FOR_CONVERGENCE_CHECK\n",
    "                    \n",
    "                    x_vals = np.arange(x_min, x_max, dx_needed)\n",
    "                    \n",
    "                    g_func_vals = self.ground_morse.energy_eigenfunction_amplitude(ground_index, x_vals)\n",
    "                    e_func_vals = self.excited_morse.energy_eigenfunction_amplitude(excited_index, x_vals)\n",
    "                    \n",
    "                    amp_to_integrate = e_func_vals * np.conj(g_func_vals)\n",
    "                    new_integral = scipy.integrate.simps(amp_to_integrate, x = x_vals)\n",
    "                     \n",
    "                    \n",
    "                    if np.isnan(new_integral):\n",
    "                        for index, data in enumerate(amp_to_integrate):\n",
    "                            if np.isnan(data):\n",
    "                                amp_to_integrate[index] = 0.0\n",
    "                        new_integral = scipy.integrate.simps(amp_to_integrate, x= x_vals)\n",
    "                    \n",
    "                    err = np.abs((new_integral - old_integral) / new_integral) \n",
    "                    \n",
    "                    calculated_integrals.append(new_integral) \n",
    "                    \n",
    "                    if  err < self.ZERO_TOLERANCE:\n",
    "                        keep_integrating = False\n",
    "                    else:\n",
    "                        number_failures += 1\n",
    "                        old_integral = new_integral\n",
    "                    if number_failures > max_failures:\n",
    "                        #It may just be that we're at zero and that's why we're unconverged\n",
    "                        if new_integral / np.max(self.franck_condon_factors) < self.ZERO_TOLERANCE:\n",
    "                            keep_integrating = False\n",
    "                        else:\n",
    "                            print(ground_index, excited_index)\n",
    "                            print( amp_to_integrate)\n",
    "                            plt.plot(calculated_integrals)\n",
    "                            plt.figure()\n",
    "                            plt.plot(amp_to_integrate)\n",
    "                            raise Exception()\n",
    "                \n",
    "                self.franck_condon_factors[ground_index, excited_index] = new_integral\n",
    "    def stick_absorption_spectrum(self, starting_ground_index):\n",
    "        relevant_FCFs = self.franck_condon_factors[starting_ground_index,:]\n",
    "        frequency_values = []\n",
    "        ground_energy = self.ground_morse.energy_eigenvalue(starting_ground_index)\n",
    "        for excited_index in range(self.excited_morse.maximum_index + 1):\n",
    "            energy_gap = self.excited_morse.energy_eigenvalue(excited_index) - ground_energy\n",
    "            frequency_values.append(energy_gap / self.hbar)\n",
    "        \n",
    "        return frequency_values, np.abs(relevant_FCFs)**2\n",
    "    \n",
    "    def total_absorption_spectrum(self, T_Kelvin):\n",
    "        all_frequencies = []\n",
    "        all_peaks = []\n",
    "        for i in range(ground.maximum_index + 1):\n",
    "            w, I = Nitrogen_offsetMorse.stick_absorption_spectrum(i)\n",
    "            thermal_weight = ground.thermal_weight_state_i(i, ROOM_TEMPERATURE_KELVIN)\n",
    "            spectrum = thermal_weight * I\n",
    "            all_frequencies.append(w)\n",
    "            all_peaks.append(spectrum)\n",
    "        all_frequencies = np.concatenate(all_frequencies)\n",
    "        all_peaks = np.concatenate(all_peaks)\n",
    "        return all_frequencies, all_peaks\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ground = Morse(system_dictionary=Nitrogen_Chi_1_Sigma_g_Plus, universe_dictionary = Nitrogen_universe_dictionary)\n",
    "excited = Morse(system_dictionary=Nitrogen_a_1_Pi_g, universe_dictionary = Nitrogen_universe_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Nitrogen_offsetMorse = OffsetMorse(ground_morse = ground, excited_morse = excited, universe_dictionary = Nitrogen_universe_dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "# for ground_i in range(ground.maximum_index):\n",
    "for ground_i in [0]:\n",
    "    x_vals = ground.x_values_for_energy_eigenfunction(ground_i)\n",
    "    f_vals = ground.energy_eigenfunction_amplitude(ground_i, x_vals)\n",
    "    plt.plot(x_vals, np.real(f_vals))\n",
    "x_vals_g = x_vals\n",
    "# plt.xlim(0, .0002)\n",
    "# plt.figure()\n",
    "for excited_i in [33]:\n",
    "    x_vals = excited.x_values_for_energy_eigenfunction(excited_i)\n",
    "    f_vals = excited.energy_eigenfunction_amplitude(excited_i, x_vals)\n",
    "    plt.plot(x_vals, np.real(f_vals))\n",
    "# plt.xlim(0, .0002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
